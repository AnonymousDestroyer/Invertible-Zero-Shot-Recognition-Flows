{"format": "torch", "nodes": [{"name": "transforms.0", "id": 140193761030672, "class_name": "AffineCoupling(\n  (nn): MLPR(\n    (nonlin): ReLU()\n    (in_layer): Linear(in_features=2, out_features=124, bias=True)\n    (out_layer): Linear(in_features=124, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=124, out_features=124, bias=True)\n      (1): Linear(in_features=124, out_features=124, bias=True)\n      (2): Linear(in_features=124, out_features=124, bias=True)\n      (3): Linear(in_features=124, out_features=124, bias=True)\n      (4): Linear(in_features=124, out_features=124, bias=True)\n      (5): Linear(in_features=124, out_features=124, bias=True)\n      (6): Linear(in_features=124, out_features=124, bias=True)\n      (7): Linear(in_features=124, out_features=124, bias=True)\n      (8): Linear(in_features=124, out_features=124, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [124, 2]], ["nn.in_layer.bias", [124]], ["nn.out_layer.weight", [4, 124]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [124, 124]], ["nn.layers.0.bias", [124]], ["nn.layers.1.weight", [124, 124]], ["nn.layers.1.bias", [124]], ["nn.layers.2.weight", [124, 124]], ["nn.layers.2.bias", [124]], ["nn.layers.3.weight", [124, 124]], ["nn.layers.3.bias", [124]], ["nn.layers.4.weight", [124, 124]], ["nn.layers.4.bias", [124]], ["nn.layers.5.weight", [124, 124]], ["nn.layers.5.bias", [124]], ["nn.layers.6.weight", [124, 124]], ["nn.layers.6.bias", [124]], ["nn.layers.7.weight", [124, 124]], ["nn.layers.7.bias", [124]], ["nn.layers.8.weight", [124, 124]], ["nn.layers.8.bias", [124]]], "output_shape": [[128, 4], [128]], "num_parameters": [248, 124, 496, 4, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124]}, {"name": "transforms.1", "id": 140193761030800, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.2", "id": 140191840961488, "class_name": "FullCombiner()", "parameters": [["w", [4, 4]]], "output_shape": [[128, 4], []], "num_parameters": [16]}, {"name": "transforms.3", "id": 140191840962192, "class_name": "AffineCoupling(\n  (nn): MLPR(\n    (nonlin): ReLU()\n    (in_layer): Linear(in_features=2, out_features=124, bias=True)\n    (out_layer): Linear(in_features=124, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=124, out_features=124, bias=True)\n      (1): Linear(in_features=124, out_features=124, bias=True)\n      (2): Linear(in_features=124, out_features=124, bias=True)\n      (3): Linear(in_features=124, out_features=124, bias=True)\n      (4): Linear(in_features=124, out_features=124, bias=True)\n      (5): Linear(in_features=124, out_features=124, bias=True)\n      (6): Linear(in_features=124, out_features=124, bias=True)\n      (7): Linear(in_features=124, out_features=124, bias=True)\n      (8): Linear(in_features=124, out_features=124, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [124, 2]], ["nn.in_layer.bias", [124]], ["nn.out_layer.weight", [4, 124]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [124, 124]], ["nn.layers.0.bias", [124]], ["nn.layers.1.weight", [124, 124]], ["nn.layers.1.bias", [124]], ["nn.layers.2.weight", [124, 124]], ["nn.layers.2.bias", [124]], ["nn.layers.3.weight", [124, 124]], ["nn.layers.3.bias", [124]], ["nn.layers.4.weight", [124, 124]], ["nn.layers.4.bias", [124]], ["nn.layers.5.weight", [124, 124]], ["nn.layers.5.bias", [124]], ["nn.layers.6.weight", [124, 124]], ["nn.layers.6.bias", [124]], ["nn.layers.7.weight", [124, 124]], ["nn.layers.7.bias", [124]], ["nn.layers.8.weight", [124, 124]], ["nn.layers.8.bias", [124]]], "output_shape": [[128, 4], [128]], "num_parameters": [248, 124, 496, 4, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124]}, {"name": "transforms.4", "id": 140193761092560, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.5", "id": 140193761094992, "class_name": "FullCombiner()", "parameters": [["w", [4, 4]]], "output_shape": [[128, 4], []], "num_parameters": [16]}, {"name": "transforms.6", "id": 140193761095184, "class_name": "AffineCoupling(\n  (nn): MLPR(\n    (nonlin): ReLU()\n    (in_layer): Linear(in_features=2, out_features=124, bias=True)\n    (out_layer): Linear(in_features=124, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=124, out_features=124, bias=True)\n      (1): Linear(in_features=124, out_features=124, bias=True)\n      (2): Linear(in_features=124, out_features=124, bias=True)\n      (3): Linear(in_features=124, out_features=124, bias=True)\n      (4): Linear(in_features=124, out_features=124, bias=True)\n      (5): Linear(in_features=124, out_features=124, bias=True)\n      (6): Linear(in_features=124, out_features=124, bias=True)\n      (7): Linear(in_features=124, out_features=124, bias=True)\n      (8): Linear(in_features=124, out_features=124, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [124, 2]], ["nn.in_layer.bias", [124]], ["nn.out_layer.weight", [4, 124]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [124, 124]], ["nn.layers.0.bias", [124]], ["nn.layers.1.weight", [124, 124]], ["nn.layers.1.bias", [124]], ["nn.layers.2.weight", [124, 124]], ["nn.layers.2.bias", [124]], ["nn.layers.3.weight", [124, 124]], ["nn.layers.3.bias", [124]], ["nn.layers.4.weight", [124, 124]], ["nn.layers.4.bias", [124]], ["nn.layers.5.weight", [124, 124]], ["nn.layers.5.bias", [124]], ["nn.layers.6.weight", [124, 124]], ["nn.layers.6.bias", [124]], ["nn.layers.7.weight", [124, 124]], ["nn.layers.7.bias", [124]], ["nn.layers.8.weight", [124, 124]], ["nn.layers.8.bias", [124]]], "output_shape": [[128, 4], [128]], "num_parameters": [248, 124, 496, 4, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124]}, {"name": "transforms.7", "id": 140193761095312, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.8", "id": 140193760593936, "class_name": "FullCombiner()", "parameters": [["w", [4, 4]]], "output_shape": [[128, 4], []], "num_parameters": [16]}, {"name": "transforms.9", "id": 140193760594000, "class_name": "AffineCoupling(\n  (nn): MLPR(\n    (nonlin): ReLU()\n    (in_layer): Linear(in_features=2, out_features=124, bias=True)\n    (out_layer): Linear(in_features=124, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=124, out_features=124, bias=True)\n      (1): Linear(in_features=124, out_features=124, bias=True)\n      (2): Linear(in_features=124, out_features=124, bias=True)\n      (3): Linear(in_features=124, out_features=124, bias=True)\n      (4): Linear(in_features=124, out_features=124, bias=True)\n      (5): Linear(in_features=124, out_features=124, bias=True)\n      (6): Linear(in_features=124, out_features=124, bias=True)\n      (7): Linear(in_features=124, out_features=124, bias=True)\n      (8): Linear(in_features=124, out_features=124, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [124, 2]], ["nn.in_layer.bias", [124]], ["nn.out_layer.weight", [4, 124]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [124, 124]], ["nn.layers.0.bias", [124]], ["nn.layers.1.weight", [124, 124]], ["nn.layers.1.bias", [124]], ["nn.layers.2.weight", [124, 124]], ["nn.layers.2.bias", [124]], ["nn.layers.3.weight", [124, 124]], ["nn.layers.3.bias", [124]], ["nn.layers.4.weight", [124, 124]], ["nn.layers.4.bias", [124]], ["nn.layers.5.weight", [124, 124]], ["nn.layers.5.bias", [124]], ["nn.layers.6.weight", [124, 124]], ["nn.layers.6.bias", [124]], ["nn.layers.7.weight", [124, 124]], ["nn.layers.7.bias", [124]], ["nn.layers.8.weight", [124, 124]], ["nn.layers.8.bias", [124]]], "output_shape": [[128, 4], [128]], "num_parameters": [248, 124, 496, 4, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124]}, {"name": "transforms.10", "id": 140193760594192, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.11", "id": 140193760166544, "class_name": "FullCombiner()", "parameters": [["w", [4, 4]]], "output_shape": [[128, 4], []], "num_parameters": [16]}, {"name": "transforms.12", "id": 140193760166736, "class_name": "AffineCoupling(\n  (nn): MLPR(\n    (nonlin): ReLU()\n    (in_layer): Linear(in_features=2, out_features=124, bias=True)\n    (out_layer): Linear(in_features=124, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=124, out_features=124, bias=True)\n      (1): Linear(in_features=124, out_features=124, bias=True)\n      (2): Linear(in_features=124, out_features=124, bias=True)\n      (3): Linear(in_features=124, out_features=124, bias=True)\n      (4): Linear(in_features=124, out_features=124, bias=True)\n      (5): Linear(in_features=124, out_features=124, bias=True)\n      (6): Linear(in_features=124, out_features=124, bias=True)\n      (7): Linear(in_features=124, out_features=124, bias=True)\n      (8): Linear(in_features=124, out_features=124, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [124, 2]], ["nn.in_layer.bias", [124]], ["nn.out_layer.weight", [4, 124]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [124, 124]], ["nn.layers.0.bias", [124]], ["nn.layers.1.weight", [124, 124]], ["nn.layers.1.bias", [124]], ["nn.layers.2.weight", [124, 124]], ["nn.layers.2.bias", [124]], ["nn.layers.3.weight", [124, 124]], ["nn.layers.3.bias", [124]], ["nn.layers.4.weight", [124, 124]], ["nn.layers.4.bias", [124]], ["nn.layers.5.weight", [124, 124]], ["nn.layers.5.bias", [124]], ["nn.layers.6.weight", [124, 124]], ["nn.layers.6.bias", [124]], ["nn.layers.7.weight", [124, 124]], ["nn.layers.7.bias", [124]], ["nn.layers.8.weight", [124, 124]], ["nn.layers.8.bias", [124]]], "output_shape": [[128, 4], [128]], "num_parameters": [248, 124, 496, 4, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124, 15376, 124]}], "edges": []}