{"format": "torch", "nodes": [{"name": "transforms.0", "id": 140210296579856, "class_name": "AffineCoupling(\n  (nn): MLP(\n    (non_linearity): ReLU()\n    (in_layer): Linear(in_features=2, out_features=128, bias=True)\n    (out_layer): Linear(in_features=128, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=128, out_features=128, bias=True)\n      (1): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [128, 2]], ["nn.in_layer.bias", [128]], ["nn.out_layer.weight", [4, 128]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [128, 128]], ["nn.layers.0.bias", [128]], ["nn.layers.1.weight", [128, 128]], ["nn.layers.1.bias", [128]]], "output_shape": [[128, 4], [128]], "num_parameters": [256, 128, 512, 4, 16384, 128, 16384, 128]}, {"name": "transforms.1", "id": 140207275548816, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.2", "id": 140207370617232, "class_name": "LinearLU()", "parameters": [["lower_entries", [6]], ["upper_entries", [6]], ["unconstrained_upper_diag", [4]]], "output_shape": [[128, 4], [128]], "num_parameters": [6, 6, 4]}, {"name": "transforms.3", "id": 140210296581456, "class_name": "AffineCoupling(\n  (nn): MLP(\n    (non_linearity): ReLU()\n    (in_layer): Linear(in_features=2, out_features=128, bias=True)\n    (out_layer): Linear(in_features=128, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=128, out_features=128, bias=True)\n      (1): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [128, 2]], ["nn.in_layer.bias", [128]], ["nn.out_layer.weight", [4, 128]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [128, 128]], ["nn.layers.0.bias", [128]], ["nn.layers.1.weight", [128, 128]], ["nn.layers.1.bias", [128]]], "output_shape": [[128, 4], [128]], "num_parameters": [256, 128, 512, 4, 16384, 128, 16384, 128]}, {"name": "transforms.4", "id": 140210296581584, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.5", "id": 140207355487248, "class_name": "LinearLU()", "parameters": [["lower_entries", [6]], ["upper_entries", [6]], ["unconstrained_upper_diag", [4]]], "output_shape": [[128, 4], [128]], "num_parameters": [6, 6, 4]}, {"name": "transforms.6", "id": 140210296046416, "class_name": "AffineCoupling(\n  (nn): MLP(\n    (non_linearity): ReLU()\n    (in_layer): Linear(in_features=2, out_features=128, bias=True)\n    (out_layer): Linear(in_features=128, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=128, out_features=128, bias=True)\n      (1): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [128, 2]], ["nn.in_layer.bias", [128]], ["nn.out_layer.weight", [4, 128]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [128, 128]], ["nn.layers.0.bias", [128]], ["nn.layers.1.weight", [128, 128]], ["nn.layers.1.bias", [128]]], "output_shape": [[128, 4], [128]], "num_parameters": [256, 128, 512, 4, 16384, 128, 16384, 128]}, {"name": "transforms.7", "id": 140210296046544, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.8", "id": 140210296046224, "class_name": "LinearLU()", "parameters": [["lower_entries", [6]], ["upper_entries", [6]], ["unconstrained_upper_diag", [4]]], "output_shape": [[128, 4], [128]], "num_parameters": [6, 6, 4]}, {"name": "transforms.9", "id": 140210296047696, "class_name": "AffineCoupling(\n  (nn): MLP(\n    (non_linearity): ReLU()\n    (in_layer): Linear(in_features=2, out_features=128, bias=True)\n    (out_layer): Linear(in_features=128, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=128, out_features=128, bias=True)\n      (1): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [128, 2]], ["nn.in_layer.bias", [128]], ["nn.out_layer.weight", [4, 128]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [128, 128]], ["nn.layers.0.bias", [128]], ["nn.layers.1.weight", [128, 128]], ["nn.layers.1.bias", [128]]], "output_shape": [[128, 4], [128]], "num_parameters": [256, 128, 512, 4, 16384, 128, 16384, 128]}, {"name": "transforms.10", "id": 140210296047888, "class_name": "ActNormBijectionCloud()", "parameters": [["shift", [1, 4]], ["log_scale", [1, 4]]], "output_shape": [[128, 4], [128]], "num_parameters": [4, 4]}, {"name": "transforms.11", "id": 140210296047632, "class_name": "LinearLU()", "parameters": [["lower_entries", [6]], ["upper_entries", [6]], ["unconstrained_upper_diag", [4]]], "output_shape": [[128, 4], [128]], "num_parameters": [6, 6, 4]}, {"name": "transforms.12", "id": 140210296049168, "class_name": "AffineCoupling(\n  (nn): MLP(\n    (non_linearity): ReLU()\n    (in_layer): Linear(in_features=2, out_features=128, bias=True)\n    (out_layer): Linear(in_features=128, out_features=4, bias=True)\n    (layers): ModuleList(\n      (0): Linear(in_features=128, out_features=128, bias=True)\n      (1): Linear(in_features=128, out_features=128, bias=True)\n    )\n  )\n)", "parameters": [["nn.in_layer.weight", [128, 2]], ["nn.in_layer.bias", [128]], ["nn.out_layer.weight", [4, 128]], ["nn.out_layer.bias", [4]], ["nn.layers.0.weight", [128, 128]], ["nn.layers.0.bias", [128]], ["nn.layers.1.weight", [128, 128]], ["nn.layers.1.bias", [128]]], "output_shape": [[128, 4], [128]], "num_parameters": [256, 128, 512, 4, 16384, 128, 16384, 128]}], "edges": []}